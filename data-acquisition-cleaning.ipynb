{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition and Cleaning\n",
    "\n",
    "This project relys on two different sources of data: United States' Bureau of Transport Statistics, and National Climatic Data Center. The fisrt source can only be accessed via its website, while the second provides an API with an extensive guide for utilising it.\n",
    "\n",
    "Bureau of Transport Statistics provides extensive statistics on various forms of transportation, including airline performance data which consists of various figures related to departure and arrival delays. Data related to any year back to 1987 can be accessed. However, given that no API is provided, the relevant data should be downloaded via a menu system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impoting the necessary python libraries\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list containing all the csv files and sorting them alphabetically\n",
    "csv_list = glob.glob('../../../../resource-datasets/capstone-data/flight-data/[0-9][0-9].csv')\n",
    "csv_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary containing the monthly weather share of delays labeled as National Aviation System delays\n",
    "weather_share_nas = {'2017-01': 0.6617,\n",
    "                     '2017-02': 0.6814,\n",
    "                     '2017-03': 0.6475,\n",
    "                     '2017-04': 0.5684,\n",
    "                     '2017-05': 0.5320,\n",
    "                     '2017-06': 0.6302,\n",
    "                     '2017-07': 0.7192,\n",
    "                     '2017-08': 0.7191,\n",
    "                     '2017-09': 0.6112,\n",
    "                     '2017-10': 0.5916,\n",
    "                     '2017-11': 0.6567,\n",
    "                     '2017-12': 0.5707,\n",
    "                     '2018-01': 0.6056,\n",
    "                     '2018-02': 0.6057,\n",
    "                     '2018-03': 0.5891,\n",
    "                     '2018-04': 0.6408,\n",
    "                     '2018-05': 0.7559,\n",
    "                     '2018-06': 0.6445,\n",
    "                     '2018-07': 0.7273,\n",
    "                     '2018-08': 0.7956,\n",
    "                     '2018-09': 0.6346,\n",
    "                     '2018-10': 0.6169,\n",
    "                     '2018-11': 0.6599,\n",
    "                     '2018-12': 0.6391,\n",
    "                     '2019-01': 0.6986,\n",
    "                     '2019-02': 0.6886,\n",
    "                     '2019-03': 0.6188,\n",
    "                     '2019-04': 0.7336,\n",
    "                     '2019-05': 0.7774,\n",
    "                     '2019-06': 0.7497,\n",
    "                     '2019-07': 0.7903,\n",
    "                     '2019-08': 0.7390,\n",
    "                     '2019-09': 0.5391,\n",
    "                     '2019-10': 0.5939,\n",
    "                     '2019-11': 0.6203,\n",
    "                     '2019-12': 0.6742}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the first csv file, changing the column names to lower case, renaming the weather_delay to\n",
    "#extreme_weather_delay for greater accuracy and extracting the weather share of NAS delays\n",
    "flight_set = pd.read_csv(csv_list[0])\n",
    "flight_set.columns = flight_set.columns.str.lower()\n",
    "flight_set.rename(columns={'weather_delay': 'extreme_weather_delay'}, inplace=True)\n",
    "flight_set['weather_delay'] = flight_set['nas_delay'] * weather_share_nas[list(weather_share_nas.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a loop to load the remaining files\n",
    "for i, file in enumerate(csv_list[1:]):\n",
    "    #loading the remaining files and concatenating the contents one by one into a single dataframe\n",
    "    next_flight_set = pd.read_csv(file)\n",
    "    next_flight_set.columns = next_flight_set.columns.str.lower()\n",
    "    next_flight_set.rename(columns={'weather_delay': 'extreme_weather_delay'}, inplace=True)\n",
    "    next_flight_set['weather_delay'] = next_flight_set['nas_delay'] * weather_share_nas[list(weather_share_nas.keys())[i]]\n",
    "    flight_set = pd.concat([flight_set, next_flight_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the top twenty airports of origin and forming a new dataframe containing the data related to these airports only\n",
    "top_twenty_origins = list(flight_set['origin'].value_counts().sort_values(ascending=False).head(20).index)\n",
    "top_twenty_airports = flight_set[flight_set['origin'].isin(top_twenty_origins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the schedulled departure time into a string\n",
    "top_twenty_airports['crs_dep_time'] = top_twenty_airports['crs_dep_time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to transform the schedulled departure time to a consistant 4-digit format\n",
    "def correct_time(cell):\n",
    "    if len(cell) == 3:\n",
    "        return '0'+cell\n",
    "    elif len(cell) == 2:\n",
    "        return '00'+cell\n",
    "    elif len(cell) == 1:\n",
    "        return '000'+cell\n",
    "    else:\n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the above function to correct the formatting\n",
    "top_twenty_airports['crs_dep_time'] = top_twenty_airports['crs_dep_time'].apply(correct_time)\n",
    "#converting the schedulled departure time to hh:mm:ss format\n",
    "top_twenty_airports['crs_dep_time'] = top_twenty_airports['crs_dep_time'].apply(lambda x: x[0: 2]+':'+x[2:]+':00')\n",
    "#combining the schedulled departure time with the departure date in order to create a single timestamp\n",
    "top_twenty_airports['dep_timestamp'] = pd.to_datetime(top_twenty_airports['fl_date']+' '+top_twenty_airports['crs_dep_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the that are no longer required and sorting the dataframe by origin\n",
    "top_twenty_airports.drop(['unnamed: 25', 'fl_date', 'crs_dep_time', 'dep_time'], axis=1, inplace=True)\n",
    "top_twenty_airports.sort_values('origin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the order inwhich the columns appear in the dataframe\n",
    "top_twenty_airports = top_twenty_airports[['dep_timestamp', 'op_unique_carrier', 'tail_num', 'origin', 'origin_city_name',\n",
    "                                            'dest', 'dest_city_name', 'dep_delay_new', 'wheels_off', 'wheels_on',\n",
    "                                            'taxi_in', 'arr_delay_new', 'cancelled', 'cancellation_code', 'diverted',\n",
    "                                            'air_time', 'distance', 'carrier_delay', 'extreme_weather_delay', 'weather_delay',\n",
    "                                            'nas_delay', 'security_delay', 'late_aircraft_delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the missing values in the various delay columns to zero\n",
    "top_twenty_airports['carrier_delay'].fillna(0, inplace=True)\n",
    "top_twenty_airports['extreme_weather_delay'].fillna(0, inplace=True)\n",
    "top_twenty_airports['weather_delay'].fillna(0, inplace=True)\n",
    "top_twenty_airports['nas_delay'].fillna(0, inplace=True)\n",
    "top_twenty_airports['security_delay'].fillna(0, inplace=True)\n",
    "top_twenty_airports['late_aircraft_delay'].fillna(0, inplace=True)\n",
    "\n",
    "#writing the dataframe into a csv file\n",
    "top_twenty_airports.to_csv('../../../../resource-datasets/capstone-data/flight-data/top-twenty-airports.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
